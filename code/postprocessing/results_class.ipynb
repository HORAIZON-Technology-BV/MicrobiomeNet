{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,accuracy_score,f1_score\n",
    "from scipy.stats import f_oneway\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['H','Y','Q']\n",
    "tasks = ['D','TL']\n",
    "sets = ['train','val','test']\n",
    "num_shuffles=50\n",
    "\n",
    "pm = u'\\u00b1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "q_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "avg_dict ={    \n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}}\n",
    "\n",
    "out_dict = {\n",
    "    'H':h_dict,\n",
    "    'Y':y_dict,\n",
    "    'Q':q_dict,\n",
    "    'avg':avg_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: H \t D\n",
      "acc: 0.851840490797546 ± 0.03865152398511716\n",
      "F1: 0.9019796580374362 ± 0.028058486791476735\n",
      "auc: 0.9056213410586035 ± 0.030442877159569785\n",
      "DATASET: H \t TL\n",
      "acc: 0.8839877300613496 ± 0.030240420700598663\n",
      "F1: 0.9250174424031242 ± 0.021127354129770078\n",
      "auc: 0.9171500995835596 ± 0.0267512091117952\n",
      "\n",
      "\n",
      "DATASET: Y \t D\n",
      "acc: 0.737258064516129 ± 0.1151966377486566\n",
      "F1: 0.7563137796831486 ± 0.14507236526224965\n",
      "auc: 0.7599891156462586 ± 0.1364723373052335\n",
      "DATASET: Y \t TL\n",
      "acc: 0.7403225806451611 ± 0.1111265742506383\n",
      "F1: 0.7651053444534438 ± 0.13863485216342497\n",
      "auc: 0.7661986394557823 ± 0.13309882795731\n",
      "\n",
      "\n",
      "DATASET: Q \t D\n",
      "acc: 0.8575 ± 0.06526654749733757\n",
      "F1: 0.8559778910698891 ± 0.07249891243482329\n",
      "auc: 0.909078260869565 ± 0.06265026639222704\n",
      "DATASET: Q \t TL\n",
      "acc: 0.8862500000000001 ± 0.05910354614290641\n",
      "F1: 0.8897913123872633 ± 0.053837823237398046\n",
      "auc: 0.9339478260869565 ± 0.056977151259039474\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "for cur_dataset in datasets:\n",
    "    for cur_task in tasks:\n",
    "        print('DATASET:',cur_dataset,'\\t',cur_task)\n",
    "        cur_set = 'test'\n",
    "        true =  pd.read_csv('../../data/output/class_'+cur_dataset+'_'+cur_task+'_'+cur_set+'.csv')\n",
    "        preds = pd.read_csv('../../data/output/class_'+cur_dataset+'_'+cur_task+'_pred_'+cur_set+'.csv')\n",
    "        auc = []\n",
    "        f1 = []\n",
    "        acc = []\n",
    "        for i in range(num_shuffles):\n",
    "            auc.append(roc_auc_score(true.iloc[:,i],preds.iloc[:,i]))\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(true.iloc[:,i], preds.iloc[:,i])\n",
    "            # get the best threshold\n",
    "            J = tpr - fpr\n",
    "            ix = np.argmax(J)\n",
    "            best_thresh = thresholds[ix]\n",
    "            # print('Best Threshold=%f' % (best_thresh))\n",
    "            \n",
    "            y_pred_binned = np.asarray(preds.iloc[:,i] > best_thresh, dtype=int)\n",
    "            f1.append(f1_score(true.iloc[:,i],y_pred_binned))\n",
    "            acc.append(accuracy_score(true.iloc[:,i],y_pred_binned))\n",
    "\n",
    "        print('acc:',np.mean(acc),pm,np.std(acc))\n",
    "        print('F1:',np.mean(f1),pm,np.std(f1))\n",
    "        print('auc:',np.mean(auc),pm,np.std(auc))\n",
    "\n",
    "        out_dict[cur_dataset]['acc'][cur_task] = acc\n",
    "        out_dict[cur_dataset]['f1'][cur_task] = f1\n",
    "        out_dict[cur_dataset]['auc'][cur_task] = auc\n",
    "        if check:\n",
    "            out_dict['avg']['acc'][cur_task] = list(acc)\n",
    "            out_dict['avg']['f1'][cur_task] = list(f1)\n",
    "            out_dict['avg']['auc'][cur_task] = list(auc)\n",
    "            \n",
    "        else:\n",
    "            out_dict['avg']['acc'][cur_task].extend(acc)\n",
    "            out_dict['avg']['f1'][cur_task].extend(f1)\n",
    "            out_dict['avg']['auc'][cur_task].extend(auc)\n",
    "    check = False\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: HMP_2019_ibdmdb \t xgb\n",
      "acc: 0.7742944785276075 ± 0.04984861723251688\n",
      "F1: 0.8450749725626372 ± 0.04240285277894101\n",
      "auc: 0.8286698050576378 ± 0.034054875236907964\n",
      "DATASET: HMP_2019_ibdmdb \t xtra\n",
      "acc: 0.7471779141104293 ± 0.05159611329351152\n",
      "F1: 0.8221610610126773 ± 0.04460274620413162\n",
      "auc: 0.8319258856901441 ± 0.03323361907562904\n",
      "\n",
      "\n",
      "DATASET: YachidaS_2019 \t xgb\n",
      "acc: 0.5764516129032258 ± 0.05347546531091172\n",
      "F1: 0.6054686108401411 ± 0.13505171310276315\n",
      "auc: 0.5481904761904761 ± 0.04448223114866596\n",
      "DATASET: YachidaS_2019 \t xtra\n",
      "acc: 0.5651612903225807 ± 0.04897067439899733\n",
      "F1: 0.5536037969949665 ± 0.12952948004493553\n",
      "auc: 0.562174149659864 ± 0.04354676336709887\n",
      "\n",
      "\n",
      "DATASET: Qinn_2014 \t xgb\n",
      "acc: 0.8854166666666667 ± 0.034673577035610914\n",
      "F1: 0.885141887892286 ± 0.03610667553641189\n",
      "auc: 0.9475478260869565 ± 0.02736213215362499\n",
      "DATASET: Qinn_2014 \t xtra\n",
      "acc: 0.8679166666666667 ± 0.0507940421921924\n",
      "F1: 0.8646472582562322 ± 0.058093250693318374\n",
      "auc: 0.9307304347826088 ± 0.038890320302518905\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['HMP_2019_ibdmdb','YachidaS_2019','Qinn_2014']\n",
    "tasks = ['xgb','xtra']\n",
    "sets = ['test']\n",
    "num_shuffles=50\n",
    "check=True\n",
    "for cur_dataset in datasets:\n",
    "    for cur_task in tasks:\n",
    "        print('DATASET:',cur_dataset,'\\t',cur_task)\n",
    "        filename = '../../data/output/tree-based/classification/'+cur_dataset+'/'+cur_task+'/test.csv'\n",
    "        test_set = pd.read_csv(filename)\n",
    "\n",
    "        auc = []\n",
    "        f1 = []\n",
    "        acc = []\n",
    "\n",
    "        for i in range(num_shuffles):\n",
    "            pred = test_set['Shuffle_'+str(i+1)+'_pred']\n",
    "            true =  test_set['Shuffle_'+str(i+1)+'_test']\n",
    "            \n",
    "            auc.append(roc_auc_score(true,pred))\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(true, pred)\n",
    "            # get the best threshold\n",
    "            J = tpr - fpr\n",
    "            ix = np.argmax(J)\n",
    "            best_thresh = thresholds[ix]\n",
    "            # print('Best Threshold=%f' % (best_thresh))\n",
    "            \n",
    "            y_pred_binned = np.asarray(pred > best_thresh, dtype=int)\n",
    "            f1.append(f1_score(true,y_pred_binned))\n",
    "            acc.append(accuracy_score(true,y_pred_binned))\n",
    "        print('acc:',np.mean(acc),pm,np.std(acc))\n",
    "        print('F1:',np.mean(f1),pm,np.std(f1))\n",
    "        print('auc:',np.mean(auc),pm,np.std(auc))\n",
    "\n",
    "        out_dict[cur_dataset[0]]['acc'][cur_task] = acc\n",
    "        out_dict[cur_dataset[0]]['f1'][cur_task] = f1\n",
    "        out_dict[cur_dataset[0]]['auc'][cur_task] = auc\n",
    "        if check:\n",
    "            out_dict['avg']['acc'][cur_task] = list(acc)\n",
    "            out_dict['avg']['f1'][cur_task] = list(f1)\n",
    "            out_dict['avg']['auc'][cur_task] = list(auc)\n",
    "            \n",
    "        else:\n",
    "            out_dict['avg']['acc'][cur_task].extend(acc)\n",
    "            out_dict['avg']['f1'][cur_task].extend(f1)\n",
    "            out_dict['avg']['auc'][cur_task].extend(auc)\n",
    "    check = False\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "acc\n",
      "('D', 'TL') 1.3397180709136862e-05 D 0.851840490797546 ± 0.03865152398511716 TL 0.8839877300613496 ± 0.030240420700598663\n",
      "('TL', 'xgb') 2.0885856814722348e-23 TL 0.8839877300613496 ± 0.030240420700598663 xgb 0.7742944785276075 ± 0.04984861723251688\n",
      "('TL', 'xtra') 4.144073524747149e-29 TL 0.8839877300613496 ± 0.030240420700598663 xtra 0.7471779141104293 ± 0.05159611329351152\n",
      "f1\n",
      "('D', 'TL') 1.3083862090014108e-05 D 0.9019796580374362 ± 0.028058486791476735 TL 0.9250174424031242 ± 0.021127354129770078\n",
      "('TL', 'xgb') 1.506313165750582e-20 TL 0.9250174424031242 ± 0.021127354129770078 xgb 0.8450749725626372 ± 0.04240285277894101\n",
      "('TL', 'xtra') 2.6442159859454055e-26 TL 0.9250174424031242 ± 0.021127354129770078 xtra 0.8221610610126773 ± 0.04460274620413162\n",
      "auc\n",
      "('D', 'TL') 0.04922906525731324 D 0.9056213410586035 ± 0.030442877159569785 TL 0.9171500995835596 ± 0.0267512091117952\n",
      "('TL', 'xgb') 9.97752124921788e-26 TL 0.9171500995835596 ± 0.0267512091117952 xgb 0.8286698050576378 ± 0.034054875236907964\n",
      "('TL', 'xtra') 4.425451580824753e-25 TL 0.9171500995835596 ± 0.0267512091117952 xtra 0.8319258856901441 ± 0.03323361907562904\n",
      "Y\n",
      "acc\n",
      "('D', 'TL') 0.8936601376697644 D 0.737258064516129 ± 0.1151966377486566 TL 0.7403225806451611 ± 0.1111265742506383\n",
      "('TL', 'xgb') 3.9725174766336155e-15 TL 0.7403225806451611 ± 0.1111265742506383 xgb 0.5764516129032258 ± 0.05347546531091172\n",
      "('TL', 'xtra') 7.464180776094643e-17 TL 0.7403225806451611 ± 0.1111265742506383 xtra 0.5651612903225807 ± 0.04897067439899733\n",
      "f1\n",
      "('D', 'TL') 0.7597313907886967 D 0.7563137796831486 ± 0.14507236526224965 TL 0.7651053444534438 ± 0.13863485216342497\n",
      "('TL', 'xgb') 9.126592834846204e-08 TL 0.7651053444534438 ± 0.13863485216342497 xgb 0.6054686108401411 ± 0.13505171310276315\n",
      "('TL', 'xtra') 6.65297034790128e-12 TL 0.7651053444534438 ± 0.13863485216342497 xtra 0.5536037969949665 ± 0.12952948004493553\n",
      "auc\n",
      "('D', 'TL') 0.8201094550913433 D 0.7599891156462586 ± 0.1364723373052335 TL 0.7661986394557823 ± 0.13309882795731\n",
      "('TL', 'xgb') 1.548103488935691e-18 TL 0.7661986394557823 ± 0.13309882795731 xgb 0.5481904761904761 ± 0.04448223114866596\n",
      "('TL', 'xtra') 4.496582681135875e-17 TL 0.7661986394557823 ± 0.13309882795731 xtra 0.562174149659864 ± 0.04354676336709887\n",
      "Q\n",
      "acc\n",
      "('D', 'TL') 0.024431285920498258 D 0.8575 ± 0.06526654749733757 TL 0.8862500000000001 ± 0.05910354614290641\n",
      "('TL', 'xgb') 0.9323326655377997 TL 0.8862500000000001 ± 0.05910354614290641 xgb 0.8854166666666667 ± 0.034673577035610914\n",
      "('TL', 'xtra') 0.10281204985717367 TL 0.8862500000000001 ± 0.05910354614290641 xtra 0.8679166666666667 ± 0.0507940421921924\n",
      "f1\n",
      "('D', 'TL') 0.010160657124832611 D 0.8559778910698891 ± 0.07249891243482329 TL 0.8897913123872633 ± 0.053837823237398046\n",
      "('TL', 'xgb') 0.6167489922320346 TL 0.8897913123872633 ± 0.053837823237398046 xgb 0.885141887892286 ± 0.03610667553641189\n",
      "('TL', 'xtra') 0.02856919850594046 TL 0.8897913123872633 ± 0.053837823237398046 xtra 0.8646472582562322 ± 0.058093250693318374\n",
      "auc\n",
      "('D', 'xgb') 0.00015333117454210818 D 0.909078260869565 ± 0.06265026639222704 xgb 0.9475478260869565 ± 0.02736213215362499\n",
      "('TL', 'xgb') 0.1352400523958153 TL 0.9339478260869565 ± 0.056977151259039474 xgb 0.9475478260869565 ± 0.02736213215362499\n",
      "('xgb', 'xtra') 0.015014041746892366 xgb 0.9475478260869565 ± 0.02736213215362499 xtra 0.9307304347826088 ± 0.038890320302518905\n",
      "avg\n",
      "acc\n",
      "('D', 'TL') 0.06439769723766643 D 0.815532851771225 ± 0.09700576680304744 TL 0.8368534369021703 ± 0.10122037996817168\n",
      "('TL', 'xgb') 2.0639032498575603e-10 TL 0.8368534369021703 ± 0.10122037996817168 xgb 0.7453875860325 ± 0.13605131611364568\n",
      "('TL', 'xtra') 2.9352880887359386e-14 TL 0.8368534369021703 ± 0.10122037996817168 xtra 0.7267519570332256 ± 0.13428397660271552\n",
      "f1\n",
      "('D', 'TL') 0.09192507720899433 D 0.838090442930158 ± 0.11281042713011007 TL 0.8599713664146104 ± 0.11058071236264903\n",
      "('TL', 'xgb') 1.8180763467629107e-07 TL 0.8599713664146104 ± 0.11058071236264903 xgb 0.7785618237650215 ± 0.1495384326821245\n",
      "('TL', 'xtra') 1.383131529064127e-11 TL 0.8599713664146104 ± 0.11058071236264903 xtra 0.7468040387546254 ± 0.16231056193593119\n",
      "auc\n",
      "('D', 'TL') 0.2791547924591523 D 0.8582295725248089 ± 0.11248596904676945 TL 0.8724321883754328 ± 0.11364675261541086\n",
      "('TL', 'xgb') 1.7073899179793657e-08 TL 0.8724321883754328 ± 0.11364675261541086 xgb 0.7748027024450234 ± 0.17125296422285557\n",
      "('TL', 'xtra') 4.326129559196824e-09 TL 0.8724321883754328 ± 0.11364675261541086 xtra 0.7749434900442056 ± 0.1605206205049796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in out_dict.keys():\n",
    "    print(dataset)\n",
    "    dataset_dict = out_dict[dataset]\n",
    "    for metric in dataset_dict.keys():\n",
    "        print(metric)\n",
    "        cur_dict = dataset_dict[metric]\n",
    "        means = {}\n",
    "        for key in cur_dict.keys():\n",
    "            means[key] = np.mean(cur_dict[key])\n",
    "        means = pd.Series(means,index=means.keys())\n",
    "        best = means.index[np.argmax(means)]\n",
    "\n",
    "        list_comb = list(itertools.combinations(cur_dict, 2))\n",
    "        for comb in list_comb:\n",
    "            if best in comb:\n",
    "                set0 = cur_dict[comb[0]]\n",
    "                set1 = cur_dict[comb[1]]\n",
    "\n",
    "                _,pval = f_oneway(set0,set1)\n",
    "\n",
    "                print(comb,pval,comb[0],np.mean(set0),pm,np.std(set0),comb[1],np.mean(set1),pm,np.std(set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "q_dict = {\n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}\n",
    "}\n",
    "\n",
    "avg_dict ={    \n",
    "    'acc':{},\n",
    "    'f1':{},\n",
    "    'auc':{}}\n",
    "\n",
    "out_dict = {\n",
    "    'H':h_dict,\n",
    "    'Y':y_dict,\n",
    "    'Q':q_dict,\n",
    "    'avg':avg_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['H','Y','Q']\n",
    "# datasets = ['Y','Q']\n",
    "tasks = ['head','first','all']\n",
    "sets = ['test']\n",
    "num_shuffles=50\n",
    "\n",
    "pm = u'\\u00b1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: H \t head\n",
      "acc: 0.6391411042944786 ± 0.08262589806137674\n",
      "F1: 0.7313820090065398 ± 0.08508308673124153\n",
      "auc: 0.681879413362303 ± 0.08102797485201023\n",
      "DATASET: H \t first\n",
      "acc: 0.8556441717791411 ± 0.041074112167561454\n",
      "F1: 0.9054348283405892 ± 0.029987099940149944\n",
      "auc: 0.8880318667390911 ± 0.029901304737890395\n",
      "DATASET: H \t all\n",
      "acc: 0.8839877300613496 ± 0.030240420700598663\n",
      "F1: 0.9250174424031242 ± 0.021127354129770078\n",
      "auc: 0.9171500995835596 ± 0.0267512091117952\n",
      "\n",
      "\n",
      "DATASET: Y \t head\n",
      "acc: 0.5445161290322581 ± 0.07377582265434024\n",
      "F1: 0.5214582099376439 ± 0.21230757432294667\n",
      "auc: 0.5158367346938776 ± 0.06863150915077712\n",
      "DATASET: Y \t first\n",
      "acc: 0.7206451612903225 ± 0.12702839162516452\n",
      "F1: 0.7466359619500337 ± 0.142364693217937\n",
      "auc: 0.7375238095238096 ± 0.16387598263129552\n",
      "DATASET: Y \t all\n",
      "acc: 0.7403225806451611 ± 0.1111265742506383\n",
      "F1: 0.7651053444534438 ± 0.13863485216342497\n",
      "auc: 0.7661986394557823 ± 0.13309882795731\n",
      "\n",
      "\n",
      "DATASET: Q \t head\n",
      "acc: 0.6841666666666667 ± 0.07942501704962569\n",
      "F1: 0.6608687055099672 ± 0.13112915924815163\n",
      "auc: 0.7055304347826088 ± 0.10459590221382664\n",
      "DATASET: Q \t first\n",
      "acc: 0.8979166666666666 ± 0.03801726581436387\n",
      "F1: 0.8972257282327658 ± 0.039680165669711914\n",
      "auc: 0.9508521739130436 ± 0.028224988593379588\n",
      "DATASET: Q \t all\n",
      "acc: 0.8862500000000001 ± 0.05910354614290641\n",
      "F1: 0.8897913123872633 ± 0.053837823237398046\n",
      "auc: 0.9339478260869565 ± 0.056977151259039474\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check=True\n",
    "for cur_dataset in datasets:\n",
    "    for cur_task in tasks:\n",
    "        print('DATASET:',cur_dataset,'\\t',cur_task)\n",
    "        cur_set = 'test'\n",
    "        true =  pd.read_csv('../../data/output/class_'+cur_dataset+'_'+'TL'+'_'+cur_task+cur_set+'.csv')\n",
    "        preds = pd.read_csv('../../data/output/class_'+cur_dataset+'_'+'TL'+'_'+cur_task+'pred_'+cur_set+'.csv')\n",
    "        auc = []\n",
    "        f1 = []\n",
    "        acc = []\n",
    "        for i in range(num_shuffles):\n",
    "            auc.append(roc_auc_score(true.iloc[:,i],preds.iloc[:,i]))\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(true.iloc[:,i], preds.iloc[:,i])\n",
    "            # get the best threshold\n",
    "            J = tpr - fpr\n",
    "            ix = np.argmax(J)\n",
    "            best_thresh = thresholds[ix]\n",
    "            # print('Best Threshold=%f' % (best_thresh))\n",
    "            \n",
    "            y_pred_binned = np.asarray(preds.iloc[:,i] > best_thresh, dtype=int)\n",
    "            f1.append(f1_score(true.iloc[:,i],y_pred_binned))\n",
    "            acc.append(accuracy_score(true.iloc[:,i],y_pred_binned))\n",
    "\n",
    "        print('acc:',np.mean(acc),pm,np.std(acc))\n",
    "        print('F1:',np.mean(f1),pm,np.std(f1))\n",
    "        print('auc:',np.mean(auc),pm,np.std(auc))\n",
    "\n",
    "        out_dict[cur_dataset]['acc'][cur_task] = acc\n",
    "        out_dict[cur_dataset]['f1'][cur_task] = f1\n",
    "        out_dict[cur_dataset]['auc'][cur_task] = auc\n",
    "        if check:\n",
    "            out_dict['avg']['acc'][cur_task] = list(acc)\n",
    "            out_dict['avg']['f1'][cur_task] = list(f1)\n",
    "            out_dict['avg']['auc'][cur_task] = list(auc)\n",
    "            \n",
    "        else:\n",
    "            out_dict['avg']['acc'][cur_task].extend(acc)\n",
    "            out_dict['avg']['f1'][cur_task].extend(f1)\n",
    "            out_dict['avg']['auc'][cur_task].extend(auc)\n",
    "    check = False\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "acc\n",
      "('head', 'all') 1.8049643378188276e-35 head 0.6391411042944786 ± 0.08262589806137674 all 0.8839877300613496 ± 0.030240420700598663\n",
      "('first', 'all') 0.00018280449712436677 first 0.8556441717791411 ± 0.041074112167561454 all 0.8839877300613496 ± 0.030240420700598663\n",
      "f1\n",
      "('head', 'all') 4.9083796668536e-28 head 0.7313820090065398 ± 0.08508308673124153 all 0.9250174424031242 ± 0.021127354129770078\n",
      "('first', 'all') 0.0003132794071865446 first 0.9054348283405892 ± 0.029987099940149944 all 0.9250174424031242 ± 0.021127354129770078\n",
      "auc\n",
      "('head', 'all') 3.7090860956565803e-35 head 0.681879413362303 ± 0.08102797485201023 all 0.9171500995835596 ± 0.0267512091117952\n",
      "('first', 'all') 1.8017053293337782e-06 first 0.8880318667390911 ± 0.029901304737890395 all 0.9171500995835596 ± 0.0267512091117952\n",
      "Y\n",
      "acc\n",
      "('head', 'all') 3.053391463263096e-17 head 0.5445161290322581 ± 0.07377582265434024 all 0.7403225806451611 ± 0.1111265742506383\n",
      "('first', 'all') 0.41640915597952555 first 0.7206451612903225 ± 0.12702839162516452 all 0.7403225806451611 ± 0.1111265742506383\n",
      "f1\n",
      "('head', 'all') 1.1723840285313723e-09 head 0.5214582099376439 ± 0.21230757432294667 all 0.7651053444534438 ± 0.13863485216342497\n",
      "('first', 'all') 0.5168199691417451 first 0.7466359619500337 ± 0.142364693217937 all 0.7651053444534438 ± 0.13863485216342497\n",
      "auc\n",
      "('head', 'all') 2.575609752056678e-20 head 0.5158367346938776 ± 0.06863150915077712 all 0.7661986394557823 ± 0.13309882795731\n",
      "('first', 'all') 0.34406119990310435 first 0.7375238095238096 ± 0.16387598263129552 all 0.7661986394557823 ± 0.13309882795731\n",
      "Q\n",
      "acc\n",
      "('head', 'first') 5.67444873722717e-31 head 0.6841666666666667 ± 0.07942501704962569 first 0.8979166666666666 ± 0.03801726581436387\n",
      "('first', 'all') 0.24801506268613127 first 0.8979166666666666 ± 0.03801726581436387 all 0.8862500000000001 ± 0.05910354614290641\n",
      "f1\n",
      "('head', 'first') 4.127610947912838e-21 head 0.6608687055099672 ± 0.13112915924815163 first 0.8972257282327658 ± 0.039680165669711914\n",
      "('first', 'all') 0.4383754409896333 first 0.8972257282327658 ± 0.039680165669711914 all 0.8897913123872633 ± 0.053837823237398046\n",
      "auc\n",
      "('head', 'first') 8.53515989026558e-29 head 0.7055304347826088 ± 0.10459590221382664 first 0.9508521739130436 ± 0.028224988593379588\n",
      "('first', 'all') 0.0657445612381831 first 0.9508521739130436 ± 0.028224988593379588 all 0.9339478260869565 ± 0.056977151259039474\n",
      "avg\n",
      "acc\n",
      "('head', 'all') 1.0856067063767593e-51 head 0.6226079666644677 ± 0.0978764487551117 all 0.8368534369021703 ± 0.10122037996817168\n",
      "('first', 'all') 0.32361439834066597 first 0.8247353332453767 ± 0.11017294771961439 all 0.8368534369021703 ± 0.10122037996817168\n",
      "f1\n",
      "('head', 'all') 3.58494022801158e-31 head 0.6379029748180503 ± 0.17543624868197957 all 0.8599713664146104 ± 0.11058071236264903\n",
      "('first', 'all') 0.4326425642877971 first 0.8497655061744628 ± 0.11362026900401107 all 0.8599713664146104 ± 0.11058071236264903\n",
      "auc\n",
      "('head', 'all') 8.432851071715443e-48 head 0.6344155276129296 ± 0.12053657829220235 all 0.8724321883754328 ± 0.11364675261541086\n",
      "('first', 'all') 0.34109704752460546 first 0.8588026167253149 ± 0.1323909548780202 all 0.8724321883754328 ± 0.11364675261541086\n"
     ]
    }
   ],
   "source": [
    "for dataset in out_dict.keys():\n",
    "    print(dataset)\n",
    "    dataset_dict = out_dict[dataset]\n",
    "    for metric in dataset_dict.keys():\n",
    "        print(metric)\n",
    "        cur_dict = dataset_dict[metric]\n",
    "        means = {}\n",
    "        for key in cur_dict.keys():\n",
    "            means[key] = np.mean(cur_dict[key])\n",
    "        means = pd.Series(means,index=means.keys())\n",
    "        best = means.index[np.argmax(means)]\n",
    "\n",
    "        list_comb = list(itertools.combinations(cur_dict, 2))\n",
    "        for comb in list_comb:\n",
    "            if best in comb:\n",
    "                set0 = cur_dict[comb[0]]\n",
    "                set1 = cur_dict[comb[1]]\n",
    "\n",
    "                _,pval = f_oneway(set0,set1)\n",
    "\n",
    "                print(comb,pval,comb[0],np.mean(set0),pm,np.std(set0),comb[1],np.mean(set1),pm,np.std(set1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
